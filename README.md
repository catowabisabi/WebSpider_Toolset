![Build Status](https://img.shields.io/badge/build-passing-brightgreen)
![License](https://img.shields.io/badge/license-MIT-blue)
![GitHub Stars](https://img.shields.io/badge/stars-0-gray)

# ğŸ¤– WebSpider Toolset / ç¶²è·¯çˆ¬èŸ²å·¥å…·é›†

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

<a name="english"></a>
## ğŸ“– Introduction
WebSpider Toolset is a comprehensive Python-based web scraping and automation framework that provides efficient and reliable tools for data collection, processing, and analysis.

## ğŸ¯ Purpose
- Build a modular and maintainable web scraping system
- Provide reusable components for common scraping tasks
- Ensure robust error handling and rate limiting
- Support multiple data sources and export formats

## âœ¨ Features
- ğŸš€ Modular architecture for easy extension
- ğŸ›¡ï¸ Built-in rate limiting and proxy support
- ğŸ“Š Data processing and export utilities
- ğŸ”„ Automatic retry mechanism
- ğŸ“ Comprehensive logging system

## âš™ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/WebSpider_Toolset.git
cd WebSpider_Toolset
```

2. Set up the environment:
```bash
# Using pip
pip install -r requirements.txt

# Or using conda
conda env create -f environment.yml
conda activate webspider
```

3. Configure environment variables:
```bash
cp .env.example .env
# Edit .env with your credentials
```

## ğŸš€ Usage

Basic usage example:
```python
from services.spider import WebSpider
from utils.config import load_config

# Initialize spider with configuration
config = load_config()
spider = WebSpider(config)

# Start scraping
data = spider.scrape("https://example.com")
```

## ğŸ“‚ Module Breakdown

- `endpoints/`: API endpoints and webhook handlers
- `services/`: Core scraping and processing logic
- `utils/`: Utility functions and helpers
- `tests/`: Unit and integration tests
- `docs/`: Documentation and resources

## ğŸ–¼ï¸ Architecture
![Architecture](docs/architecture.png)

## ğŸ“„ License
This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contribution
Contributions are welcome! Please feel free to submit a Pull Request.

---

<a name="ä¸­æ–‡"></a>
## ğŸ“– ç°¡ä»‹
WebSpider Toolset æ˜¯ä¸€å€‹å…¨é¢çš„ Python ç¶²è·¯çˆ¬èŸ²å’Œè‡ªå‹•åŒ–æ¡†æ¶ï¼Œæä¾›é«˜æ•ˆä¸”å¯é çš„æ•¸æ“šæ¡é›†ã€è™•ç†å’Œåˆ†æå·¥å…·ã€‚

## ğŸ¯ ç”¨é€”
- å»ºç«‹æ¨¡çµ„åŒ–ä¸”æ˜“æ–¼ç¶­è­·çš„ç¶²è·¯çˆ¬èŸ²ç³»çµ±
- æä¾›å¯é‡ç”¨çš„å¸¸è¦‹çˆ¬èŸ²ä»»å‹™å…ƒä»¶
- ç¢ºä¿å¼·å¤§çš„éŒ¯èª¤è™•ç†å’Œé€Ÿç‡é™åˆ¶
- æ”¯æ´å¤šç¨®æ•¸æ“šä¾†æºå’Œå°å‡ºæ ¼å¼

## âœ¨ ä¸»è¦åŠŸèƒ½
- ğŸš€ æ¨¡çµ„åŒ–æ¶æ§‹ï¼Œæ˜“æ–¼æ“´å±•
- ğŸ›¡ï¸ å…§å»ºé€Ÿç‡é™åˆ¶å’Œä»£ç†æ”¯æ´
- ğŸ“Š æ•¸æ“šè™•ç†å’Œå°å‡ºå·¥å…·
- ğŸ”„ è‡ªå‹•é‡è©¦æ©Ÿåˆ¶
- ğŸ“ å®Œæ•´çš„æ—¥èªŒç³»çµ±

## âš™ï¸ å®‰è£æ–¹å¼

1. å…‹éš†å°ˆæ¡ˆï¼š
```bash
git clone https://github.com/yourusername/WebSpider_Toolset.git
cd WebSpider_Toolset
```

2. è¨­ç½®ç’°å¢ƒï¼š
```bash
# ä½¿ç”¨ pip
pip install -r requirements.txt

# æˆ–ä½¿ç”¨ conda
conda env create -f environment.yml
conda activate webspider
```

3. é…ç½®ç’°å¢ƒè®Šæ•¸ï¼š
```bash
cp .env.example .env
# ç·¨è¼¯ .env å¡«å…¥æ‚¨çš„æ†‘è­‰
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹ï¼š
```python
from services.spider import WebSpider
from utils.config import load_config

# åˆå§‹åŒ–çˆ¬èŸ²èˆ‡é…ç½®
config = load_config()
spider = WebSpider(config)

# é–‹å§‹çˆ¬å–
data = spider.scrape("https://example.com")
```

## ğŸ“‚ æ¨¡çµ„èªªæ˜

- `endpoints/`: API ç«¯é»å’Œ webhook è™•ç†å™¨
- `services/`: æ ¸å¿ƒçˆ¬èŸ²å’Œè™•ç†é‚è¼¯
- `utils/`: å·¥å…·å‡½æ•¸å’Œè¼”åŠ©ç¨‹å¼
- `tests/`: å–®å…ƒå’Œæ•´åˆæ¸¬è©¦
- `docs/`: æ–‡æª”å’Œè³‡æº

## ğŸ–¼ï¸ æ¶æ§‹åœ–
![æ¶æ§‹åœ–](docs/architecture.png)

## ğŸ“„ æˆæ¬Š
æœ¬å°ˆæ¡ˆæ¡ç”¨ MIT æˆæ¬Š - è©³è¦‹ LICENSE æ–‡ä»¶ã€‚

## ğŸ¤ è²¢ç»æ–¹å¼
æ­¡è¿è²¢ç»ï¼è«‹éš¨æ™‚æäº¤ Pull Requestã€‚ 